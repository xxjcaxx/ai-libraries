https://github.com/Disservin/chess-library
https://mesonbuild.com/

meson setup build
meson compile -C build

compile in ubuntu 22.04 for libraries

board = chess.Board()
board.set_fen(positions[frame]) 



Parece que **`concat_fen_legal_bits` est谩 tardando 1.3 segundos en ejecutarse** dentro de tu pipeline de Monte Carlo Tree Search (MCTS). Esto sugiere que la conversi贸n de la representaci贸n FEN a un tensor binario comprimido es un cuello de botella notable en el rendimiento.  

---

### **Posibles optimizaciones**
1. **Evitar `new` y usar arrays est谩ticos**  
   - Actualmente, en `concat_fen_legal`, creas din谩micamente `fen_matrix_legal_moves` con `new Matrix3D77()`, lo cual puede ser costoso.  
   - Mejor usa una **variable local est谩tica** para evitar asignaciones din谩micas.

2. **Reducir copias de memoria**  
   - **`std::copy(fen_matrix.begin(), fen_matrix.end(), combinedArray.begin());`** y **`std::copy(legal_moves.begin(), legal_moves.end(), combinedArray.begin() + fen_matrix.size());`** hacen copias innecesarias.  
   - Si los datos ya est谩n organizados en memoria contigua, podr铆as usar **pointers o `std::memcpy`** en lugar de `std::copy`.

3. **Optimizar la conversi贸n de `uint64_t` a `uint8_t`**  
   - Actualmente, **el bucle que descompone los `uint64_t` en bytes es costoso**.  
   - En lugar de iterar sobre cada byte con `>>` y `&`, podr铆as hacer **una reinterpretaci贸n de memoria (`reinterpret_cast`)** si la alineaci贸n lo permite.

4. **Vectorizaci贸n con SIMD (AVX2, NEON, etc.)**  
   - Si tu CPU soporta instrucciones vectoriales (SIMD), puedes paralelizar la extracci贸n de bytes con AVX2 en x86 o NEON en ARM.

5. **Uso de OpenMP o paralelizaci贸n con CUDA**  
   - Si `concat_fen_legal_bits` es un cuello de botella importante, podr铆as paralelizar la conversi贸n usando **OpenMP** (para CPU) o incluso mover la conversi贸n a **CUDA** si est谩s usando `torch.cuda`.

---

### **Pr贸ximos pasos**
1. **Mide el impacto real de `concat_fen_legal_bits`**:  
   - Si es solo **1.3s de 18.4s (~7%)**, tal vez no sea el problema principal.
   - Usa `cProfile` o `torch.profiler` para analizar cuellos de botella m谩s profundos.

2. **Aplica optimizaciones progresivamente**:  
   - Prueba primero la eliminaci贸n de `new` y la optimizaci贸n de copias.
   - Luego intenta `memcpy` y reinterpretaci贸n de memoria.
   - Si a煤n es lento, investiga SIMD y paralelizaci贸n.

驴Quieres ayuda con una versi贸n optimizada del c贸digo? 